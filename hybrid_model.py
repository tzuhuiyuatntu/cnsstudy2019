# Demo Code of the Hybrid Model


#import modules
import os
import tempfile
import sys
import csv
import pandas as pd
import numpy as np
import tensorflow as tf
import deepchem as dc
import deepchem.metrics
from sklearn import preprocessing, svm
from sklearn.metrics import f1_score, roc_auc_score, accuracy_score


#Stage 1 - GCN
#set up
low_memory=False
np.set_printoptions(threshold=sys.maxsize)
tasks = ['value']
graph_featurizer = dc.feat.graph_features.ConvMolFeaturizer()
loader = dc.data.data_loader.CSVLoader( tasks = tasks, smiles_field = "smiles", id_field = "name",featurizer = graph_featurizer)
dataset = loader.featurize( '../data_set/DataGNNMain.csv' )  # import the main data set
testset = loader.featurize( '../data_set/DataGNNTest.csv' )  # import the external test set

#split files into train/valid and create files
splitter = dc.splits.splitters.FingerprintSplitter()
train_inds, valid_inds, test_inds1 = splitter.split( dataset , seed = 3, frac_train=.8, frac_valid=.2, frac_test=0)
train_dir = tempfile.mkdtemp()
trainset = dataset.select(train_inds, train_dir)
valid_dir = tempfile.mkdtemp()
validset = dataset.select(valid_inds, valid_dir)
model_dir = 'models/model'

#run
batch_size=[16]
graph_conv_layers=[[64,64]]
dense_layer_size=[64]
dropout=[0.4]
final_tv_score = 0
for bs in batch_size:
    for gcl in graph_conv_layers:
        for dls in dense_layer_size:
            for do in dropout:
                if not os.path.exists(model_dir):
                    os.makedirs(model_dir)
                model = dc.models.tensorgraph.models.graph_models.GraphConvTensorGraph(1, batch_size=bs,
                                                                                    graph_conv_layers=gcl,
                                                                                    dense_layer_size=dls,
                                                                                    learning_rate=0.001,
                                                                                    dropout=do,mode='classification')
                model.model_dir = model_dir
                final_valid_score=0
                for i in range(300):
                        model.fit(trainset, nb_epoch=1)
                        train_scores = {}
                        valid_scores= {}
                        test_scores = {}
                        metric = dc.metrics.Metric(dc.metrics.accuracy_score, np.mean, mode="classification")
                        valid_scores = model.evaluate(validset, [metric])
                        valid_test_score = valid_scores["mean-accuracy_score"]
                        if valid_test_score > final_valid_score:
                            train_scores = model.evaluate(trainset, [metric])
                            final_test_score = train_scores["mean-accuracy_score"]
                            test_scores = model.evaluate(testset, [metric])
                            final_test_score = test_scores["mean-accuracy_score"]
                            final_tv_score = valid_test_score
                            final_valid_score = valid_test_score
                            predicted_train = model.predict(trainset)
                            predicted_valid = model.predict(validset)
                            predicted_test = model.predict(testset)


smiles_train = trainset.ids
smiles_valid = validset.ids
smiles_test = testset.ids


# Stage 2 - SVM

"""
Before this part, researchers should calculate molecular descriptors first.
In our study, we use PaDEL-Descriptor to read in SMILES lists generated by the GCN model (smiles_trains/smiles_valid/smiles_test).
PaDEL-Descriptor will output multiple descriptors in csv formats.
"""

# import PaDEL descriptors
train_file_path = "../data_set/padel_raw_train.csv"
train = pd.read_csv(train_file_path)  # import the train set with molecular descriptors
valid_file_path = "../data_set/padel_raw_valid.csv"
valid = pd.read_csv(valid_file_path)  # import the valid set with molecular descriptors
test_file_path = "../data_set/padel_test.csv"
test = pd.read_csv(test_file_path)    # import the test set with molecular descriptors
predictors=[]
f=open(r"descriptor_set/final_svm_gnn_20.txt")
predictors=f.readlines()
f.close()
for i in range(0,len(predictors)):
    predictors[i]=predictors[i].strip("\n")

# preprocess data
x_train = np.array(train[predictors], dtype=int)
x_valid = np.array(valid[predictors], dtype=int)
x_test = np.array(test[predictors], dtype=int)
y_train = np.array(train.output, dtype=int)
y_valid = np.array(valid.output, dtype=int)
y_test = np.array(test.output, dtype=int)
x_train = preprocessing.scale(x_train)
x_valid = preprocessing.scale(x_valid)
x_test = preprocessing.scale(x_test)

# combine SVM and DL algorighms
x_train = np.column_stack((x_train, train_pred))
x_valid = np.column_stack((x_valid, valid_pred))
x_test = np.column_stack((x_test, test_pred))
svc_model = svm.SVC(kernel='linear', C=0.01, probability=True).fit(x_train, y_train)
svm_y_train_pred = svc_model.predict(x_train)
svm_y_test_pred = svc_model.predict(x_valid)
svm_y_ex_pred = svc_model.predict(x_test)

# evaluation
print(f'Train Accuracy Score: {accuracy_score(y_train, svm_y_train_pred)}')
print(f'Valid Accuracy Score: {accuracy_score(y_valid, svm_y_test_pred)}')
print(f'Test Accuracy Score: {accuracy_score(y_test, svm_y_ex_pred)}')  
print(f'Train ROC AUC  Score: {roc_auc_score(y_train, svm_train_prob[:, 1])}')
print(f'Valid ROC AUC  Score: {roc_auc_score(y_valid, svm_valid_prob[:, 1])}')
print(f'Test ROC AUC Score: {roc_auc_score(y_test, svm_test_prob[:, 1])}')  
print(f'Train f1 Score: {f1_score(y_train, svm_y_train_pred)}')
print(f'Valid f1 Score: {f1_score(y_valid, svm_y_test_pred)}')
print(f'Test f1 Score: {f1_score(y_test, svm_y_ex_pred)}')  

# descriptor importance
predictors.append("pred_prob")
for i in range(len(predictors)):
    print( svc_model.coef_[0][i],predictors[i])  

